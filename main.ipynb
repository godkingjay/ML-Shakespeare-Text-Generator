{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = tf.keras.utils.get_file('shakespeare.txt', './data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text[100000:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
    "index_to_char = dict((i, c) for i, c in enumerate(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 64\n",
    "STEP_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "next_characters = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
    "  sentences.append(text[i: i + SEQ_LENGTH])\n",
    "  next_characters.append(text[i + SEQ_LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(sentences), SEQ_LENGTH, len(characters)), dtype=np.bool_)\n",
    "Y = np.zeros((len(sentences), len(characters)), dtype=np.bool_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(sentences):\n",
    "  for t, character in enumerate(sentence):\n",
    "    X[i, t, char_to_index[character]] = 1\n",
    "  Y[i, char_to_index[next_characters[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "440/440 [==============================] - 47s 102ms/step - loss: 2.2119\n",
      "Epoch 2/10\n",
      "440/440 [==============================] - 41s 94ms/step - loss: 1.7740\n",
      "Epoch 3/10\n",
      "440/440 [==============================] - 45s 103ms/step - loss: 1.6290\n",
      "Epoch 4/10\n",
      "440/440 [==============================] - 45s 102ms/step - loss: 1.5469\n",
      "Epoch 5/10\n",
      "440/440 [==============================] - 43s 98ms/step - loss: 1.4918\n",
      "Epoch 6/10\n",
      "440/440 [==============================] - 47s 106ms/step - loss: 1.4475\n",
      "Epoch 7/10\n",
      "440/440 [==============================] - 48s 110ms/step - loss: 1.4135\n",
      "Epoch 8/10\n",
      "440/440 [==============================] - 46s 105ms/step - loss: 1.3838\n",
      "Epoch 9/10\n",
      "440/440 [==============================] - 45s 102ms/step - loss: 1.3605\n",
      "Epoch 10/10\n",
      "440/440 [==============================] - 44s 101ms/step - loss: 1.3420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d6235331c0>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(SEQ_LENGTH, len(characters))))\n",
    "model.add(Dense(len(characters)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01))\n",
    "csv_logger = tf.keras.callbacks.CSVLogger('./training_log/log.csv', separator=',', append=True)\n",
    "\n",
    "model.fit(X, Y, batch_size=256, epochs=10, callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: textgenerator.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: textgenerator.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('textgenerator.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('textgenerator.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "  preds = np.asarray(preds).astype('float64')\n",
    "  preds = np.log(preds)/temperature\n",
    "  exp_preds = np.exp(preds)\n",
    "  preds = exp_preds / np.sum(exp_preds)\n",
    "  probas = np.random.multinomial(1, preds, 1)\n",
    "  return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(length, temperature):\n",
    "  start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
    "  generated = ''\n",
    "  sentence = text[start_index: start_index + SEQ_LENGTH]\n",
    "  generated += sentence\n",
    "  for i in range(length):\n",
    "    A = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
    "    for t, character in enumerate(sentence):\n",
    "      A[0, t, char_to_index[character]] = 1\n",
    "    \n",
    "    predictions = model.predict(A, verbose=0)[0]\n",
    "    next_index = sample(predictions, temperature)\n",
    "    next_character = index_to_char[next_index]\n",
    "\n",
    "    generated += next_character\n",
    "    sentence = sentence[1:] + next_character\n",
    "  \n",
    "  return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------0.2-------------------------------\n",
      "e rigour of the statute,\n",
      "to make him an example. all hope is goness.\n",
      "\n",
      "gloucester:\n",
      "i will the comest with the comest to the wife.\n",
      "\n",
      "gloucester:\n",
      "i will the charch and his hearth the comest to the will.\n",
      "\n",
      "gloucester:\n",
      "ay, but in the sin the shall the willors,\n",
      "and so a sir, and the come to the duke to the will.\n",
      "\n",
      "clarence:\n",
      "why\n",
      "-----------------------------0.4-------------------------------\n",
      ".\n",
      "\n",
      "juliet:\n",
      "hist! romeo, hist! o, for a falconer's voice,\n",
      "to lure can with the royal not for the fire\n",
      "to see the blasted with his her like, and sir,\n",
      "i will the court in the his dishorsely heard\n",
      "and she the come to the children, the fire\n",
      "that i will the hands, the willowed with the comest to the trait\n",
      "brow hold upon the \n",
      "-----------------------------0.6-------------------------------\n",
      "not know,\n",
      "which a dismiss'd offence would after gall;\n",
      "and do him he they the my tent but one executio\n",
      "where's the reason that i and good my leaved\n",
      "a soul and subjects of night, is this let thee\n",
      "say the strates of the growifilom in his ever' brows.\n",
      "\n",
      "polixenes:\n",
      "deather to the sinth the clorded in the mind,\n",
      "with think rom\n",
      "-----------------------------0.8-------------------------------\n",
      " on.\n",
      "\n",
      "mamillius:\n",
      "dwelt by a churchyard: i will tell it softly;\n",
      "you how in alive his cluees is the lost bood would\n",
      "bradsh here for the grave the goos here, like monessines!\n",
      "\n",
      "queen elizabeth:\n",
      "thy me we efel thee away all of the earth:\n",
      "i wa'll the house, where's you are they would be not tifned\n",
      "the court all 'twixt wheref\n",
      "------------------------------1--------------------------------\n",
      "rvice:\n",
      "this day my sister should the cloister enter\n",
      "and there reafles mark murd provent to accorsh.\n",
      "\n",
      "prince:\n",
      "the ovarwond merfily too offer thing, and thing\n",
      "thanker crie us my brother, aly u as.\n",
      "\n",
      "leontes:\n",
      "that shooke the wans.\n",
      "\n",
      "?\n",
      "\n",
      "cases:\n",
      "viryord they i londs wa reless a freselch,\n",
      "when my glory, is or her.\n",
      "\n",
      "isabel:\n",
      "and \n"
     ]
    }
   ],
   "source": [
    "print('-----------------------------0.2-------------------------------')\n",
    "print(generate_text(256, 0.2))\n",
    "print('-----------------------------0.4-------------------------------')\n",
    "print(generate_text(256, 0.4))\n",
    "print('-----------------------------0.6-------------------------------')\n",
    "print(generate_text(256, 0.6))\n",
    "print('-----------------------------0.8-------------------------------')\n",
    "print(generate_text(256, 0.8))\n",
    "print('------------------------------1--------------------------------')\n",
    "print(generate_text(256, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b021351d9dd0e3394eb4e5cf29f14f11ef0f3872d778219a21ef40ecdad7b36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
