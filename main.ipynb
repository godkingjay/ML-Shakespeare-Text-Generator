{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = tf.keras.utils.get_file('shakespeare.txt', './data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text[100000:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
    "index_to_char = dict((i, c) for i, c in enumerate(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 48\n",
    "STEP_SIZE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "next_characters = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
    "  sentences.append(text[i: i + SEQ_LENGTH])\n",
    "  next_characters.append(text[i + SEQ_LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(sentences), SEQ_LENGTH, len(characters)), dtype=np.bool_)\n",
    "Y = np.zeros((len(sentences), len(characters)), dtype=np.bool_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(sentences):\n",
    "  for t, character in enumerate(sentence):\n",
    "    X[i, t, char_to_index[character]] = 1\n",
    "  Y[i, char_to_index[next_characters[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1172/1172 [==============================] - 86s 72ms/step - loss: 1.9272\n",
      "Epoch 2/20\n",
      "1172/1172 [==============================] - 85s 73ms/step - loss: 1.5807\n",
      "Epoch 3/20\n",
      "1172/1172 [==============================] - 86s 73ms/step - loss: 1.4987\n",
      "Epoch 4/20\n",
      "1172/1172 [==============================] - 86s 74ms/step - loss: 1.4564\n",
      "Epoch 5/20\n",
      "1172/1172 [==============================] - 88s 75ms/step - loss: 1.4283\n",
      "Epoch 6/20\n",
      "1172/1172 [==============================] - 88s 75ms/step - loss: 1.4083\n",
      "Epoch 7/20\n",
      "1172/1172 [==============================] - 88s 75ms/step - loss: 1.3933\n",
      "Epoch 8/20\n",
      "1172/1172 [==============================] - 88s 75ms/step - loss: 1.3801\n",
      "Epoch 9/20\n",
      "1172/1172 [==============================] - 89s 76ms/step - loss: 1.3707\n",
      "Epoch 10/20\n",
      "1172/1172 [==============================] - 88s 75ms/step - loss: 1.3625\n",
      "Epoch 11/20\n",
      "1172/1172 [==============================] - 89s 76ms/step - loss: 1.3562\n",
      "Epoch 12/20\n",
      "1172/1172 [==============================] - 88s 75ms/step - loss: 1.3495\n",
      "Epoch 13/20\n",
      "1172/1172 [==============================] - 88s 75ms/step - loss: 1.3435\n",
      "Epoch 14/20\n",
      "1172/1172 [==============================] - 88s 75ms/step - loss: 1.3378\n",
      "Epoch 15/20\n",
      "1172/1172 [==============================] - 89s 76ms/step - loss: 1.3326\n",
      "Epoch 16/20\n",
      "1172/1172 [==============================] - 89s 76ms/step - loss: 1.3277\n",
      "Epoch 17/20\n",
      "1172/1172 [==============================] - 89s 76ms/step - loss: 1.3247\n",
      "Epoch 18/20\n",
      "1172/1172 [==============================] - 88s 75ms/step - loss: 1.3200\n",
      "Epoch 19/20\n",
      "1172/1172 [==============================] - 87s 75ms/step - loss: 1.3159\n",
      "Epoch 20/20\n",
      "1172/1172 [==============================] - 87s 74ms/step - loss: 1.3128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d6593e2e80>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(SEQ_LENGTH, len(characters))))\n",
    "model.add(Dense(len(characters)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01))\n",
    "csv_logger = tf.keras.callbacks.CSVLogger('./training_log/log.csv', separator=',', append=True)\n",
    "\n",
    "model.fit(X, Y, batch_size=256, epochs=20, callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_21_layer_call_fn, lstm_cell_21_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: textgenerator.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: textgenerator.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('textgenerator.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('textgenerator.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "  preds = np.asarray(preds).astype('float64')\n",
    "  preds = np.log(preds)/temperature\n",
    "  exp_preds = np.exp(preds)\n",
    "  preds = exp_preds / np.sum(exp_preds)\n",
    "  probas = np.random.multinomial(1, preds, 1)\n",
    "  return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(length, temperature):\n",
    "  start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
    "  generated = ''\n",
    "  sentence = text[start_index: start_index + SEQ_LENGTH]\n",
    "  generated += sentence\n",
    "  for i in range(length):\n",
    "    A = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
    "    for t, character in enumerate(sentence):\n",
    "      A[0, t, char_to_index[character]] = 1\n",
    "    \n",
    "    predictions = model.predict(A, verbose=0)[0]\n",
    "    next_index = sample(predictions, temperature)\n",
    "    next_character = index_to_char[next_index]\n",
    "\n",
    "    generated += next_character\n",
    "    sentence = sentence[1:] + next_character\n",
    "  \n",
    "  return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------0.2-------------------------------\n",
      "sh'd, does exceed you all.\n",
      "\n",
      "brutus:\n",
      "well, well, the first than the count thou art thoughts,\n",
      "that i have send the world that i have send\n",
      "his son than the bed to the blood to the\n",
      "lord angelo's death, and the great the prince.\n",
      "\n",
      "romeo:\n",
      "i will not see the best the country's death.\n",
      "\n",
      "pompey:\n",
      "what shall i the b\n",
      "-----------------------------0.4-------------------------------\n",
      "nd we hear\n",
      "such goodness of your justice, that one send\n",
      "him in the offers she hath been for my conding.\n",
      "\n",
      "gloucester:\n",
      "which is the poison of the sister of the crown,\n",
      "that thou art thou art to her orance and the sens\n",
      "in the conceit to the prince's strain'd conclany\n",
      "that which you have still not be not to \n",
      "-----------------------------0.6-------------------------------\n",
      "s: guess, but by my entertainment\n",
      "with him, if thou wilt diserves the crown.\n",
      "\n",
      "leontes:\n",
      "this is the brother, if thou art true field.\n",
      "\n",
      "provost:\n",
      "ay, if thou art though and here to land of face,\n",
      "and the find repent that i have show'd by the\n",
      "comfort the sight, profits the privilion should be\n",
      "stratch'd with t\n",
      "-----------------------------0.8-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\glori\\AppData\\Local\\Temp\\ipykernel_18336\\388290196.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  preds = np.log(preds)/temperature\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "but lusty, young, and cheerly drawing breath.\n",
      "look her partice in with dave must seeming\n",
      "that be not go leave and send and fellow,\n",
      "from a montages of my heart. you know not hear:\n",
      "and you have king by the men for pleasene.\n",
      "\n",
      "duke vincentio:\n",
      "look her desain's in good that shall she should be-gone\n",
      "matter bl\n",
      "------------------------------1--------------------------------\n",
      "eps in capel's monument,\n",
      "and her immortal part with the tring tratwal vows.\n",
      "\n",
      "isabella:\n",
      "\n",
      "hortess:\n",
      "syering himself.\n",
      "\n",
      "usbraal:\n",
      "in scoonge to make thy face?\n",
      "\n",
      "provost:\n",
      "for well, in thy of at what man,\n",
      "and i'll through imprison from me, there believed\n",
      "hath undoning so is store to ever his york?\n",
      "\n",
      "vols:\n",
      "that wa\n"
     ]
    }
   ],
   "source": [
    "print('-----------------------------0.2-------------------------------')\n",
    "print(generate_text(256, 0.2))\n",
    "print('-----------------------------0.4-------------------------------')\n",
    "print(generate_text(256, 0.4))\n",
    "print('-----------------------------0.6-------------------------------')\n",
    "print(generate_text(256, 0.6))\n",
    "print('-----------------------------0.8-------------------------------')\n",
    "print(generate_text(256, 0.8))\n",
    "print('------------------------------1--------------------------------')\n",
    "print(generate_text(256, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b021351d9dd0e3394eb4e5cf29f14f11ef0f3872d778219a21ef40ecdad7b36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
