{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = tf.keras.utils.get_file('shakespeare.txt', './data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text[100000:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
    "index_to_char = dict((i, c) for i, c in enumerate(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 48\n",
    "STEP_SIZE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "next_characters = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
    "  sentences.append(text[i: i + SEQ_LENGTH])\n",
    "  next_characters.append(text[i + SEQ_LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(sentences), SEQ_LENGTH, len(characters)), dtype=np.bool_)\n",
    "Y = np.zeros((len(sentences), len(characters)), dtype=np.bool_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(sentences):\n",
    "  for t, character in enumerate(sentence):\n",
    "    X[i, t, char_to_index[character]] = 1\n",
    "  Y[i, char_to_index[next_characters[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1172/1172 [==============================] - 146s 121ms/step - loss: 1.9256\n",
      "Epoch 2/5\n",
      "1172/1172 [==============================] - 140s 119ms/step - loss: 1.5771\n",
      "Epoch 3/5\n",
      "1172/1172 [==============================] - 146s 124ms/step - loss: 1.4965\n",
      "Epoch 4/5\n",
      "1172/1172 [==============================] - 159s 135ms/step - loss: 1.4538\n",
      "Epoch 5/5\n",
      "1172/1172 [==============================] - 139s 119ms/step - loss: 1.4259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x273bce239d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(SEQ_LENGTH, len(characters))))\n",
    "model.add(Dense(len(characters)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01))\n",
    "csv_logger = tf.keras.callbacks.CSVLogger('./training_log/log.csv', separator=',', append=True)\n",
    "\n",
    "model.fit(X, Y, batch_size=256, epochs=5, callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: textgenerator.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: textgenerator.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('textgenerator.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('textgenerator.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "  preds = np.asarray(preds).astype('float64')\n",
    "  preds = np.log(preds)/temperature\n",
    "  exp_preds = np.exp(preds)\n",
    "  preds = exp_preds / np.sum(exp_preds)\n",
    "  probas = np.random.multinomial(1, preds, 1)\n",
    "  return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(length, temperature):\n",
    "  start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
    "  generated = ''\n",
    "  sentence = text[start_index: start_index + SEQ_LENGTH]\n",
    "  generated += sentence\n",
    "  for i in range(length):\n",
    "    A = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
    "    for t, character in enumerate(sentence):\n",
    "      A[0, t, char_to_index[character]] = 1\n",
    "    \n",
    "    predictions = model.predict(A, verbose=0)[0]\n",
    "    next_index = sample(predictions, temperature)\n",
    "    next_character = index_to_char[next_index]\n",
    "\n",
    "    generated += next_character\n",
    "    sentence = sentence[1:] + next_character\n",
    "  \n",
    "  return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------0.2-------------------------------\n",
      "ll how to term it.\n",
      "\n",
      "first servingman:\n",
      "he had so; the say the fearing of the death and the\n",
      "deed and the hand be state of the head and the strain\n",
      "to the head and the sould so heart the death,\n",
      "and the proper the strains and in the blother,\n",
      "and the heaven of the heart the straight of the head.\n",
      "\n",
      "clarence:\n",
      "i \n",
      "-----------------------------0.4-------------------------------\n",
      "e foresaid prunes,--\n",
      "\n",
      "froth:\n",
      "ay, so i did indeed the death:\n",
      "and with his time and the bloth her sense,\n",
      "which was not so mean the friends and the fracuers\n",
      "as a man to me to the state of the gremis me\n",
      "this bear the honour of your following.\n",
      "\n",
      "corizeang:\n",
      "i am her state in a king of the state.\n",
      "\n",
      "duchess:\n",
      "thy \n",
      "-----------------------------0.6-------------------------------\n",
      "d, early next thursday morn,\n",
      "the gallant, young the bless her be a prusted,\n",
      "bear the sensence to the heavy ne'er should were of the souls\n",
      "of subject for the blort. wherefore a partens.\n",
      "\n",
      "petrich:\n",
      "sir, thou are the ampent all the countryno\n",
      "your does with such look of his love with the life\n",
      "in that from th\n",
      "-----------------------------0.8-------------------------------\n",
      " a mystery:\n",
      "but what mystery there should be in desparter,\n",
      "would come such hate them of sentence.\n",
      "\n",
      "leontes:\n",
      "a prosperity shower come so the\n",
      "the restors, in your friends' feelful love.\n",
      "believe the better my prison, betument thee.\n",
      "\n",
      "king richard iii:\n",
      "therefore.\n",
      "\n",
      "leontes:\n",
      "seen do had eaving hope he will sta\n",
      "------------------------------1--------------------------------\n",
      "the bowels of the land\n",
      "have we march'd on without in uppose thy forcemen,\n",
      "against thy lovy sbeek say intold w'd is king.\n",
      "but, and a arms brother: her housef has!\n",
      "i come to our vistan and sainted know'd\n",
      "the covarge sit det forwaste, thy born is gearty the\n",
      "too so not? not, be deslood law put is,\n",
      "is you , \n"
     ]
    }
   ],
   "source": [
    "print('-----------------------------0.2-------------------------------')\n",
    "print(generate_text(256, 0.2))\n",
    "print('-----------------------------0.4-------------------------------')\n",
    "print(generate_text(256, 0.4))\n",
    "print('-----------------------------0.6-------------------------------')\n",
    "print(generate_text(256, 0.6))\n",
    "print('-----------------------------0.8-------------------------------')\n",
    "print(generate_text(256, 0.8))\n",
    "print('------------------------------1--------------------------------')\n",
    "print(generate_text(256, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b021351d9dd0e3394eb4e5cf29f14f11ef0f3872d778219a21ef40ecdad7b36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
