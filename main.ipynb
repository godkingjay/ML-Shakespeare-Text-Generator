{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = tf.keras.utils.get_file('shakespeare.txt', './data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text[100000:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
    "index_to_char = dict((i, c) for i, c in enumerate(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 40\n",
    "STEP_SIZE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "next_characters = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
    "  sentences.append(text[i: i + SEQ_LENGTH])\n",
    "  next_characters.append(text[i + SEQ_LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(sentences), SEQ_LENGTH, len(characters)), dtype=np.bool_)\n",
    "Y = np.zeros((len(sentences), len(characters)), dtype=np.bool_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(sentences):\n",
    "  for t, character in enumerate(sentence):\n",
    "    X[i, t, char_to_index[character]] = 1\n",
    "  Y[i, char_to_index[next_characters[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1172/1172 [==============================] - 125s 103ms/step - loss: 1.9319\n",
      "Epoch 2/10\n",
      "1172/1172 [==============================] - 116s 99ms/step - loss: 1.5867\n",
      "Epoch 3/10\n",
      "1172/1172 [==============================] - 117s 100ms/step - loss: 1.5050\n",
      "Epoch 4/10\n",
      "1172/1172 [==============================] - 116s 99ms/step - loss: 1.4602\n",
      "Epoch 5/10\n",
      "1172/1172 [==============================] - 116s 99ms/step - loss: 1.4316\n",
      "Epoch 6/10\n",
      "1172/1172 [==============================] - 115s 99ms/step - loss: 1.4115\n",
      "Epoch 7/10\n",
      "1172/1172 [==============================] - 95s 81ms/step - loss: 1.3948\n",
      "Epoch 8/10\n",
      "1172/1172 [==============================] - 75s 64ms/step - loss: 1.3821\n",
      "Epoch 9/10\n",
      "1172/1172 [==============================] - 74s 63ms/step - loss: 1.3727\n",
      "Epoch 10/10\n",
      "1172/1172 [==============================] - 74s 63ms/step - loss: 1.3631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d626392f70>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(SEQ_LENGTH, len(characters))))\n",
    "model.add(Dense(len(characters)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01))\n",
    "csv_logger = tf.keras.callbacks.CSVLogger('./training_log/log.csv', separator=',', append=True)\n",
    "\n",
    "model.fit(X, Y, batch_size=256, epochs=10, callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: textgenerator.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: textgenerator.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('textgenerator.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('textgenerator.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "  preds = np.asarray(preds).astype('float64')\n",
    "  preds = np.log(preds)/temperature\n",
    "  exp_preds = np.exp(preds)\n",
    "  preds = exp_preds / np.sum(exp_preds)\n",
    "  probas = np.random.multinomial(1, preds, 1)\n",
    "  return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(length, temperature):\n",
    "  start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
    "  generated = ''\n",
    "  sentence = text[start_index: start_index + SEQ_LENGTH]\n",
    "  generated += sentence\n",
    "  for i in range(length):\n",
    "    X = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
    "    for t, character in enumerate(sentence):\n",
    "      X[0, t, char_to_index[character]] = 1\n",
    "    \n",
    "    predictions = model.predict(X, verbose=0)[0]\n",
    "    next_index = sample(predictions, temperature)\n",
    "    next_character = index_to_char[next_index]\n",
    "\n",
    "    generated += next_character\n",
    "    sentence = sentence[1:] + next_character\n",
    "  \n",
    "  return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------0.2-------------------------------\n",
      "e sound that tells what hour it is\n",
      "are clamorous grows with the world and the world,\n",
      "they shall be a manners the way to my son,\n",
      "the lord of the world be a man, and there is not\n",
      "the and the winds the world and still the great all\n",
      "and the that to the strind the sense, the to thee\n",
      "to the mother and the waster and the state\n",
      "of the world of your heart o\n",
      "-----------------------------0.4-------------------------------\n",
      "jove to humble him to her hand.\n",
      "when with his knee in men with the sense,\n",
      "the happy so man to be with his palsed\n",
      "that is the greater of my lord and be the grace.\n",
      "\n",
      "second servingment:\n",
      "i princery, not with me the most grace.\n",
      "\n",
      "second murdere:\n",
      "there is the wind the way to the sweet as i am\n",
      "nor the wind man to good pardon her heavens\n",
      "that this way of th\n",
      "-----------------------------0.6-------------------------------\n",
      " like to be loud weather;\n",
      "besides, this place is from of his heads bethe\n",
      "good clost the thought and in the stinds the restards;\n",
      "and that man prosperous richard of the sire\n",
      "till you do my matter is hereverence,\n",
      "and the restert and say part master both me\n",
      "the holy for man; her heaven my head of the thought\n",
      "the setter of the stinder unto the grief,\n",
      "ma\n",
      "-----------------------------0.8-------------------------------\n",
      " be hanged, sir, if he wear your livery:\n",
      "marry, go, he the general thee? along thee took of my york:\n",
      "they i must to be a party and in thee,\n",
      "i'll feen love it in the senter his house.\n",
      "\n",
      "gloucesterl:\n",
      "what's thy soulst if that i will very stone.\n",
      "i would thou shalt of your soul will presence in\n",
      "truth god in the arms the but mistress\n",
      "and hence, i widves,\n",
      "------------------------------1--------------------------------\n",
      "\n",
      "and he that throws not up his cap for joy\n",
      "shall from her friendly hand when shalt is not swead\n",
      "with his princelt at wedge both, sir?\n",
      "\n",
      "claudio:\n",
      "come, their heart.\n",
      "\n",
      "buckingham:\n",
      "kay, anwear the water is love it. lay i never\n",
      "busting is the kings: yet encert, but to the danger\n",
      "did in itleul up, love affender me.\n",
      "\n",
      "buckingham:\n",
      "\n",
      "gloucestenur:\n",
      "thy soldiers\n"
     ]
    }
   ],
   "source": [
    "print('-----------------------------0.2-------------------------------')\n",
    "print(generate_text(300, 0.2))\n",
    "print('-----------------------------0.4-------------------------------')\n",
    "print(generate_text(300, 0.4))\n",
    "print('-----------------------------0.6-------------------------------')\n",
    "print(generate_text(300, 0.6))\n",
    "print('-----------------------------0.8-------------------------------')\n",
    "print(generate_text(300, 0.8))\n",
    "print('------------------------------1--------------------------------')\n",
    "print(generate_text(300, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b021351d9dd0e3394eb4e5cf29f14f11ef0f3872d778219a21ef40ecdad7b36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
